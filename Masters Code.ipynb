{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vuxfoAN5-GZn",
        "IvyX2NGs-uEL",
        "peEc70-SEGKv",
        "kNJB9tAyRleK",
        "k0_JCJ_rSJZ-",
        "jO0d9OAESLu7",
        "SpNUlqwXSbX-",
        "zJCTYp7ZSmL4",
        "gMVmtLD9fdAc",
        "GjGR9xYth1PD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Prerequisites**\n",
        "will need to have\n",
        "1. A fundamental knowledge of Python programming language.\n",
        "2. A fundamental knowledge in Machine Learning.\n",
        "3. Jupyter Notebook/ Jupyter Lab/ Google Colab."
      ],
      "metadata": {
        "id": "ojPBXgVBxV2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "PhIJD7Ldx67F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance \n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade pandas-datareader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Pc19-8yh9A",
        "outputId": "7904446d-107d-41bc-beb1-2d7bf6c52588"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.84-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Installing collected packages: requests, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed requests-2.28.1 yfinance-0.1.84\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Collecting pandas-datareader\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.28.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.3.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.9.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
            "Installing collected packages: pandas-datareader\n",
            "  Attempting uninstall: pandas-datareader\n",
            "    Found existing installation: pandas-datareader 0.9.0\n",
            "    Uninstalling pandas-datareader-0.9.0:\n",
            "      Successfully uninstalled pandas-datareader-0.9.0\n",
            "Successfully installed pandas-datareader-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNgWAamLeBrt",
        "outputId": "97e80968-639a-4add-b669-2bc6bc4ab3e6"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pandas_datareader as web\n",
        "import datetime as dt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "# Scaling libraries\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler, MaxAbsScaler, RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer, Binarizer\n",
        "\n",
        "# Machine learning libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor,ExtraTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "\n",
        "# evaluation libraries\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.svm import SVR \n",
        "\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "0fjnYmSpxrW8"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load Data**"
      ],
      "metadata": {
        "id": "xTmF0z-ly5we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"\"\n",
        "\n",
        "# Input details to check\n",
        "\n",
        "# Input Start Date\n",
        "def start_date():\n",
        "    date_entry = input('Enter a starting date in MM/DD/YYYY format: ')\n",
        "    start = dt.datetime.strptime(date_entry,'%m/%d/%Y')\n",
        "    start = start.strftime('%Y-%m-%d')\n",
        "    return start\n",
        "\n",
        "# Input End Date\n",
        "def end_date():\n",
        "    date_entry = input('Enter a ending date in MM/DD/YYYY format: ')\n",
        "    end = dt.datetime.strptime(date_entry,'%m/%d/%Y')\n",
        "    end = end.strftime('%Y-%m-%d')\n",
        "    return end\n",
        "\n",
        "# Input Symbols\n",
        "def input_symbol():\n",
        "    symbol = input(\"Enter symbol: \").upper()\n",
        "    return symbol\n",
        "\n",
        "# load Dataset\n",
        "def load_data():\n",
        "\n",
        "    start = start_date()\n",
        "    end = end_date()\n",
        "    ticker = input_symbol()\n",
        "\n",
        "    \n",
        "    data = web.DataReader(ticker, 'yahoo', start, end)\n",
        "    #data = yf.download(ticker, start, end)\n",
        "    \n",
        "    return data"
      ],
      "metadata": {
        "id": "wx1JNA5CzAi0"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock data \n",
        "StockData = load_data()\n",
        "\n",
        "#Show data\n",
        "StockData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "sOC1PTPfzTUr",
        "outputId": "321c5164-774b-4c32-9763-017c75e3e607"
      },
      "execution_count": 115,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a starting date in MM/DD/YYYY format: 01/01/2011\n",
            "Enter a ending date in MM/DD/YYYY format: 01/01/2022\n",
            "Enter symbol: amzn\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  High         Low        Open       Close     Volume  \\\n",
              "Date                                                                    \n",
              "2011-01-03    9.300000    9.060500    9.068500    9.211000  106628000   \n",
              "2011-01-04    9.385000    9.189000    9.307500    9.250500  100636000   \n",
              "2011-01-05    9.372500    9.203500    9.205000    9.371000   68376000   \n",
              "2011-01-06    9.370500    9.262500    9.325000    9.293000   63594000   \n",
              "2011-01-07    9.422500    9.187000    9.394000    9.274500  104434000   \n",
              "...                ...         ...         ...         ...        ...   \n",
              "2021-12-27  172.942993  169.215500  171.037003  169.669495   58688000   \n",
              "2021-12-28  172.175995  169.135498  170.182495  170.660995   54638000   \n",
              "2021-12-29  171.212006  168.600494  170.839996  169.201004   35754000   \n",
              "2021-12-30  170.888000  168.524002  169.699997  168.644501   37584000   \n",
              "2021-12-31  169.350006  166.558502  168.955994  166.716995   47830000   \n",
              "\n",
              "             Adj Close  \n",
              "Date                    \n",
              "2011-01-03    9.211000  \n",
              "2011-01-04    9.250500  \n",
              "2011-01-05    9.371000  \n",
              "2011-01-06    9.293000  \n",
              "2011-01-07    9.274500  \n",
              "...                ...  \n",
              "2021-12-27  169.669495  \n",
              "2021-12-28  170.660995  \n",
              "2021-12-29  169.201004  \n",
              "2021-12-30  168.644501  \n",
              "2021-12-31  166.716995  \n",
              "\n",
              "[2769 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70b7fc77-976e-4bee-9917-338bd2a1e2ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>9.300000</td>\n",
              "      <td>9.060500</td>\n",
              "      <td>9.068500</td>\n",
              "      <td>9.211000</td>\n",
              "      <td>106628000</td>\n",
              "      <td>9.211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>9.385000</td>\n",
              "      <td>9.189000</td>\n",
              "      <td>9.307500</td>\n",
              "      <td>9.250500</td>\n",
              "      <td>100636000</td>\n",
              "      <td>9.250500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>9.372500</td>\n",
              "      <td>9.203500</td>\n",
              "      <td>9.205000</td>\n",
              "      <td>9.371000</td>\n",
              "      <td>68376000</td>\n",
              "      <td>9.371000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>9.370500</td>\n",
              "      <td>9.262500</td>\n",
              "      <td>9.325000</td>\n",
              "      <td>9.293000</td>\n",
              "      <td>63594000</td>\n",
              "      <td>9.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>9.422500</td>\n",
              "      <td>9.187000</td>\n",
              "      <td>9.394000</td>\n",
              "      <td>9.274500</td>\n",
              "      <td>104434000</td>\n",
              "      <td>9.274500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-27</th>\n",
              "      <td>172.942993</td>\n",
              "      <td>169.215500</td>\n",
              "      <td>171.037003</td>\n",
              "      <td>169.669495</td>\n",
              "      <td>58688000</td>\n",
              "      <td>169.669495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-28</th>\n",
              "      <td>172.175995</td>\n",
              "      <td>169.135498</td>\n",
              "      <td>170.182495</td>\n",
              "      <td>170.660995</td>\n",
              "      <td>54638000</td>\n",
              "      <td>170.660995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-29</th>\n",
              "      <td>171.212006</td>\n",
              "      <td>168.600494</td>\n",
              "      <td>170.839996</td>\n",
              "      <td>169.201004</td>\n",
              "      <td>35754000</td>\n",
              "      <td>169.201004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-30</th>\n",
              "      <td>170.888000</td>\n",
              "      <td>168.524002</td>\n",
              "      <td>169.699997</td>\n",
              "      <td>168.644501</td>\n",
              "      <td>37584000</td>\n",
              "      <td>168.644501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>169.350006</td>\n",
              "      <td>166.558502</td>\n",
              "      <td>168.955994</td>\n",
              "      <td>166.716995</td>\n",
              "      <td>47830000</td>\n",
              "      <td>166.716995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2769 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70b7fc77-976e-4bee-9917-338bd2a1e2ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70b7fc77-976e-4bee-9917-338bd2a1e2ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70b7fc77-976e-4bee-9917-338bd2a1e2ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring Dataset**"
      ],
      "metadata": {
        "id": "EzR2j9OtzrLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "StockData.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9ycEDVB0GDT",
        "outputId": "d3e26420-3c39-42ae-fccf-e5534d1e3d35"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2769, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset description\n",
        "print(StockData.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_BIKVjF0QPY",
        "outputId": "0d0f20cd-6ea0-413f-c6a1-098b8b975515"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2769 entries, 2011-01-03 to 2021-12-31\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   High       2769 non-null   float64\n",
            " 1   Low        2769 non-null   float64\n",
            " 2   Open       2769 non-null   float64\n",
            " 3   Close      2769 non-null   float64\n",
            " 4   Volume     2769 non-null   int64  \n",
            " 5   Adj Close  2769 non-null   float64\n",
            "dtypes: float64(5), int64(1)\n",
            "memory usage: 151.4 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset consist 6 columns where 5 are floats and one is an integer, all columns are in a good state hence there is no need to replace or remove rows  "
      ],
      "metadata": {
        "id": "8X_q7A910fXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# viaualise \"Close\" attribute to see market trend\n",
        "closeplot = StockData['Close'].copy()\n",
        "\n",
        "plt.plot(closeplot, color=\"green\", label=f\"Close {ticker} price\")\n",
        "plt.title(f\"{ticker} Share Close Price \")\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel(f'{ticker} Share Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5awZyfak1_hl",
        "outputId": "21deaf51-8bec-4ed3-9860-fd36ee61f604"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the data with Pearson's and Spearman's Correlation Coefficent\n",
        "# this was done to find columns (independent variables) in the dataset which \n",
        "# affect the expenditure (dependent variable)\n",
        "plt.figure(figsize=(20, 8)) \n",
        "plt.subplot(1, 2, 1)\n",
        "corr = StockData.corr(method = 'pearson')\n",
        "sns.heatmap(corr, annot = True)\n",
        "plt.title(\"Pearson Correlation\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "corr = StockData.corr(method = 'spearman')\n",
        "sns.heatmap(corr, annot = True)\n",
        "plt.title(\"Spearman Correlation\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "BMNJU1BP1pF5",
        "outputId": "cf086a83-654e-4d50-dfd3-575d102ff419"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing Data**"
      ],
      "metadata": {
        "id": "D2dGY5-o1HjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this, we select the set of attributes that directly affect the dependent variables (Close) in our dataset:"
      ],
      "metadata": {
        "id": "MvtBswST2iX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features =  ['High', 'Low', 'Open','Adj Close']\n"
      ],
      "metadata": {
        "id": "QSST9TDA1V-M"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then split the data between y(dependent) and X(independent) variables:"
      ],
      "metadata": {
        "id": "LXbaWvpy51Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = StockData.Close\n",
        "x = StockData[features]"
      ],
      "metadata": {
        "id": "piNsJBV955c_"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3MKys3g45Ge",
        "outputId": "e00f6da5-07cb-416b-bf15-4ff6c282ef98"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date\n",
            "2011-01-03      9.211000\n",
            "2011-01-04      9.250500\n",
            "2011-01-05      9.371000\n",
            "2011-01-06      9.293000\n",
            "2011-01-07      9.274500\n",
            "                 ...    \n",
            "2021-12-27    169.669495\n",
            "2021-12-28    170.660995\n",
            "2021-12-29    169.201004\n",
            "2021-12-30    168.644501\n",
            "2021-12-31    166.716995\n",
            "Name: Close, Length: 2769, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we  split our dataset into the training set and testing set in the ratios of 80:20:"
      ],
      "metadata": {
        "id": "mzcze7DL7MTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.7, random_state=1)"
      ],
      "metadata": {
        "id": "EdCLP2_E74PX"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split dataset into training and testing datasets\n",
        "def split(dataset):\n",
        "  # In this, we select the set of attributes that directly affect the dependent variables (Close) in our dataset:\n",
        "  features =  ['High', 'Low', 'Open','Adj Close']\n",
        "\n",
        "  # Then split the data between y(dependent) and X(independent) variables:\n",
        "  y = dataset['Close']\n",
        "  x = dataset[features]\n",
        "\n",
        "  # After that, we split our dataset into the training set and testing set in the ratios of 80:20:\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.7, random_state=1)\n",
        "  return X_train, X_test, Y_train, Y_test"
      ],
      "metadata": {
        "id": "8skHml2wEbc_"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fitting the Models (Before Scaling)**"
      ],
      "metadata": {
        "id": "n-2vm0FH8hRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM**"
      ],
      "metadata": {
        "id": "vuxfoAN5-GZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = svm.LinearSVR()\n",
        "# fitting model\n",
        "classifier.fit(X_train,Y_train)\n",
        "# predict\n",
        "Y_predict = classifier.predict(X_test)\n",
        "# check accuracy\n",
        "accuracy_b4 = classifier.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "5DR9kTqb830J"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of SVM before Scaling') \n",
        "print(accuracy_b4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJZTzSCW_yMH",
        "outputId": "f499d1b2-1911-4559-c2ac-10e15049b50a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of SVM before Scaling\n",
            "0.9999999417807311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check R2\n",
        "r2_b4 = r2_score(Y_test, Y_predict)\n",
        "print('R2 of SVM before Scaling') \n",
        "print(r2_b4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbYuErMXtYPg",
        "outputId": "b344bdd9-38c3-4c18-a197-49da5b887f20"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 of SVM before Scaling\n",
            "0.9999999417807311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check RMSE\n",
        "rmse_b4 = mean_squared_error(Y_test, Y_predict, squared=False)\n",
        "print('RMSE of SVM before Scaling') \n",
        "print(rmse_b4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3nnFkfRwIPR",
        "outputId": "4187b22f-811d-437e-a2a7-0587a1d1996a"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of SVM before Scaling\n",
            "0.01260930226452146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check MAPE\n",
        "mape_b4 = mean_absolute_percentage_error(Y_test, Y_predict)\n",
        "print('MAPE of SVM before Scaling') \n",
        "print(mape_b4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC9YsHBaygl_",
        "outputId": "05fa7164-6f98-4f64-96b2-aecef72e7126"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE of SVM before Scaling\n",
            "0.00012099855746256524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **linear Regression**"
      ],
      "metadata": {
        "id": "IvyX2NGs-uEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2 = LinearRegression()\n",
        "# fitting model\n",
        "classifier2.fit(X_train,Y_train)\n",
        "# predict\n",
        "Y_predict_lin = classifier2.predict(X_test)\n",
        "# check accuracy\n",
        "accuracy_b4_lin = classifier2.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "r3Lu8oT20bRE"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check accuracy\n",
        "print('Accuracy of Linear Regression before Scaling \\n') \n",
        "print(accuracy_b4_lin)\n",
        "\n",
        "# check R2\n",
        "r2_b4_lin = r2_score(Y_test, Y_predict_lin)\n",
        "print('R2 of Linear Regression before Scaling \\n') \n",
        "print(r2_b4)\n",
        "\n",
        "# Check RMSE\n",
        "rmse_b4_lin = mean_squared_error(Y_test, Y_predict_lin, squared=False)\n",
        "print('RMSE of Linear Regression before Scaling \\n') \n",
        "print(rmse_b4_lin)\n",
        "\n",
        "# Check MAPE\n",
        "mape_b4_lin = mean_absolute_percentage_error(Y_test, Y_predict_lin)\n",
        "print('MAPE of Linear Regression before Scaling \\n') \n",
        "print(mape_b4_lin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7ETLXRy4xs6",
        "outputId": "3ce815b0-3218-480a-a1e7-101f84b1040a"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Linear Regression before Scaling \n",
            "\n",
            "1.0\n",
            "R2 of Linear Regression before Scaling \n",
            "\n",
            "0.9999999417807311\n",
            "RMSE of Linear Regression before Scaling \n",
            "\n",
            "7.032334375143089e-15\n",
            "MAPE of Linear Regression before Scaling \n",
            "\n",
            "3.580171107965614e-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Scaling**"
      ],
      "metadata": {
        "id": "peEc70-SEGKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Standardizer**"
      ],
      "metadata": {
        "id": "kNJB9tAyRleK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standadizer(data):\n",
        "    workdata = data.copy()\n",
        "\n",
        "    col = []\n",
        "    for col_name in workdata.columns:\n",
        "      if workdata[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      standardScaling = StandardScaler().fit(workdata[[i]])\n",
        "      workdata[i] = standardScaling.transform(workdata[[i]])\n",
        "    return workdata\n",
        "  \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "0S2lzCB2Sr4O"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standard_Stock_Data = standadizer(StockData)\n",
        "standard_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "YBqy0qazULuE",
        "outputId": "9bf5c952-63a3-4ed2-ca52-19ca21123ac2"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                High       Low      Open     Close    Volume  Adj Close\n",
              "Date                                                                   \n",
              "2011-01-03 -0.921898 -0.923320 -0.924818 -0.922432  0.485254  -0.922432\n",
              "2011-01-04 -0.920294 -0.920840 -0.920261 -0.921678  0.355534  -0.921678\n",
              "2011-01-05 -0.920530 -0.920560 -0.922215 -0.919379 -0.342859  -0.919379\n",
              "2011-01-06 -0.920568 -0.919422 -0.919927 -0.920867 -0.446384  -0.920867\n",
              "2011-01-07 -0.919587 -0.920879 -0.918612 -0.921220  0.437756  -0.921220\n",
              "2011-01-10 -0.922567 -0.922065 -0.921319 -0.921993 -0.361433  -0.921993\n",
              "2011-01-11 -0.921898 -0.921390 -0.920957 -0.922318 -0.604637  -0.922318\n",
              "2011-01-12 -0.922483 -0.921303 -0.921014 -0.922566 -0.663132  -0.922566\n",
              "2011-01-13 -0.921473 -0.921101 -0.922692 -0.921182 -0.365287  -0.921182\n",
              "2011-01-14 -0.919124 -0.919740 -0.920881 -0.918110 -0.237212  -0.918110"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a3be0a3-2ca8-44da-ab09-bd4cdbaad27e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>-0.921898</td>\n",
              "      <td>-0.923320</td>\n",
              "      <td>-0.924818</td>\n",
              "      <td>-0.922432</td>\n",
              "      <td>0.485254</td>\n",
              "      <td>-0.922432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>-0.920294</td>\n",
              "      <td>-0.920840</td>\n",
              "      <td>-0.920261</td>\n",
              "      <td>-0.921678</td>\n",
              "      <td>0.355534</td>\n",
              "      <td>-0.921678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>-0.920530</td>\n",
              "      <td>-0.920560</td>\n",
              "      <td>-0.922215</td>\n",
              "      <td>-0.919379</td>\n",
              "      <td>-0.342859</td>\n",
              "      <td>-0.919379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>-0.920568</td>\n",
              "      <td>-0.919422</td>\n",
              "      <td>-0.919927</td>\n",
              "      <td>-0.920867</td>\n",
              "      <td>-0.446384</td>\n",
              "      <td>-0.920867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>-0.919587</td>\n",
              "      <td>-0.920879</td>\n",
              "      <td>-0.918612</td>\n",
              "      <td>-0.921220</td>\n",
              "      <td>0.437756</td>\n",
              "      <td>-0.921220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>-0.922567</td>\n",
              "      <td>-0.922065</td>\n",
              "      <td>-0.921319</td>\n",
              "      <td>-0.921993</td>\n",
              "      <td>-0.361433</td>\n",
              "      <td>-0.921993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>-0.921898</td>\n",
              "      <td>-0.921390</td>\n",
              "      <td>-0.920957</td>\n",
              "      <td>-0.922318</td>\n",
              "      <td>-0.604637</td>\n",
              "      <td>-0.922318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>-0.922483</td>\n",
              "      <td>-0.921303</td>\n",
              "      <td>-0.921014</td>\n",
              "      <td>-0.922566</td>\n",
              "      <td>-0.663132</td>\n",
              "      <td>-0.922566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>-0.921473</td>\n",
              "      <td>-0.921101</td>\n",
              "      <td>-0.922692</td>\n",
              "      <td>-0.921182</td>\n",
              "      <td>-0.365287</td>\n",
              "      <td>-0.921182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>-0.919124</td>\n",
              "      <td>-0.919740</td>\n",
              "      <td>-0.920881</td>\n",
              "      <td>-0.918110</td>\n",
              "      <td>-0.237212</td>\n",
              "      <td>-0.918110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a3be0a3-2ca8-44da-ab09-bd4cdbaad27e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a3be0a3-2ca8-44da-ab09-bd4cdbaad27e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a3be0a3-2ca8-44da-ab09-bd4cdbaad27e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **MinMax Scaling / Normalizing**"
      ],
      "metadata": {
        "id": "k0_JCJ_rSJZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minMax(data):\n",
        "    workdata1 = data.copy()\n",
        "    col = []\n",
        "    for col_name in workdata1.columns:\n",
        "      if workdata1[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      minMaxScaling = MinMaxScaler(feature_range=(0,1)).fit(workdata1[[i]])\n",
        "      workdata1[i] = minMaxScaling.transform(workdata1[[i]])\n",
        "    return workdata1"
      ],
      "metadata": {
        "id": "Srj0A77PVHHW"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minMax_Stock_Data = minMax(StockData)\n",
        "minMax_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "EbToxdUzVaf-",
        "outputId": "92872328-b957-4462-9bc0-06559e1d57c7"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                High       Low      Open     Close    Volume  Adj Close\n",
              "Date                                                                   \n",
              "2011-01-03  0.006222  0.005831  0.005632  0.006512  0.191378   0.006512\n",
              "2011-01-04  0.006693  0.006558  0.006967  0.006733  0.178494   0.006733\n",
              "2011-01-05  0.006624  0.006640  0.006394  0.007408  0.109126   0.007408\n",
              "2011-01-06  0.006613  0.006974  0.007064  0.006971  0.098844   0.006971\n",
              "2011-01-07  0.006901  0.006547  0.007449  0.006868  0.186661   0.006868\n",
              "2011-01-10  0.006026  0.006199  0.006657  0.006641  0.107281   0.006641\n",
              "2011-01-11  0.006222  0.006397  0.006763  0.006545  0.083125   0.006545\n",
              "2011-01-12  0.006051  0.006422  0.006746  0.006473  0.077315   0.006473\n",
              "2011-01-13  0.006347  0.006482  0.006255  0.006879  0.106898   0.006879\n",
              "2011-01-14  0.007037  0.006880  0.006785  0.007781  0.119619   0.007781"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53f23779-b61b-4f15-8860-bf397330ecfa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>0.006222</td>\n",
              "      <td>0.005831</td>\n",
              "      <td>0.005632</td>\n",
              "      <td>0.006512</td>\n",
              "      <td>0.191378</td>\n",
              "      <td>0.006512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>0.006693</td>\n",
              "      <td>0.006558</td>\n",
              "      <td>0.006967</td>\n",
              "      <td>0.006733</td>\n",
              "      <td>0.178494</td>\n",
              "      <td>0.006733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>0.006624</td>\n",
              "      <td>0.006640</td>\n",
              "      <td>0.006394</td>\n",
              "      <td>0.007408</td>\n",
              "      <td>0.109126</td>\n",
              "      <td>0.007408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>0.006613</td>\n",
              "      <td>0.006974</td>\n",
              "      <td>0.007064</td>\n",
              "      <td>0.006971</td>\n",
              "      <td>0.098844</td>\n",
              "      <td>0.006971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>0.006901</td>\n",
              "      <td>0.006547</td>\n",
              "      <td>0.007449</td>\n",
              "      <td>0.006868</td>\n",
              "      <td>0.186661</td>\n",
              "      <td>0.006868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>0.006026</td>\n",
              "      <td>0.006199</td>\n",
              "      <td>0.006657</td>\n",
              "      <td>0.006641</td>\n",
              "      <td>0.107281</td>\n",
              "      <td>0.006641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>0.006222</td>\n",
              "      <td>0.006397</td>\n",
              "      <td>0.006763</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>0.083125</td>\n",
              "      <td>0.006545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>0.006051</td>\n",
              "      <td>0.006422</td>\n",
              "      <td>0.006746</td>\n",
              "      <td>0.006473</td>\n",
              "      <td>0.077315</td>\n",
              "      <td>0.006473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>0.006347</td>\n",
              "      <td>0.006482</td>\n",
              "      <td>0.006255</td>\n",
              "      <td>0.006879</td>\n",
              "      <td>0.106898</td>\n",
              "      <td>0.006879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>0.007037</td>\n",
              "      <td>0.006880</td>\n",
              "      <td>0.006785</td>\n",
              "      <td>0.007781</td>\n",
              "      <td>0.119619</td>\n",
              "      <td>0.007781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53f23779-b61b-4f15-8860-bf397330ecfa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53f23779-b61b-4f15-8860-bf397330ecfa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53f23779-b61b-4f15-8860-bf397330ecfa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Binarizer**"
      ],
      "metadata": {
        "id": "jO0d9OAESLu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binirized(data):\n",
        "    workdata2 = data.copy()\n",
        "    col = []\n",
        "    for col_name in workdata2.columns:\n",
        "      if workdata2[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      binscaling = Binarizer(threshold = 0.0).fit(workdata2[[i]])\n",
        "      workdata2[i] = binscaling.transform(workdata2[[i]])\n",
        "    return workdata2"
      ],
      "metadata": {
        "id": "UI_EQAzLYE3Y"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binirized_Stock_Data = binirized(StockData)\n",
        "binirized_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "3YWWQLoDYTuI",
        "outputId": "fd0ceead-22c9-4989-faad-7b6899d71efe"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            High  Low  Open  Close  Volume  Adj Close\n",
              "Date                                                 \n",
              "2011-01-03   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-04   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-05   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-06   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-07   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-10   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-11   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-12   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-13   1.0  1.0   1.0    1.0       1        1.0\n",
              "2011-01-14   1.0  1.0   1.0    1.0       1        1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82cb6ccb-73e9-4d74-9767-c70b1ae59fee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82cb6ccb-73e9-4d74-9767-c70b1ae59fee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82cb6ccb-73e9-4d74-9767-c70b1ae59fee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82cb6ccb-73e9-4d74-9767-c70b1ae59fee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Quantile Scaling**"
      ],
      "metadata": {
        "id": "SpNUlqwXSbX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantile_scale(data):\n",
        "    workdata3 = data.copy()\n",
        "    col = []\n",
        "    for col_name in workdata3.columns:\n",
        "      if workdata3[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      quantScaling = QuantileTransformer(n_quantiles=10, random_state=0).fit(workdata3[[i]])\n",
        "      workdata3[i] = quantScaling.transform(workdata3[[i]])\n",
        "    return workdata3"
      ],
      "metadata": {
        "id": "HELnjp6UY2ST"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Quant_Stock_Data = quantile_scale(StockData)\n",
        "Quant_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "HXKhmOmpZPK-",
        "outputId": "e196e598-97d8-4493-e309-c3be53494453"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                High       Low      Open     Close    Volume  Adj Close\n",
              "Date                                                                   \n",
              "2011-01-03  0.044898  0.042911  0.040324  0.045970  0.791512   0.045970\n",
              "2011-01-04  0.048296  0.048259  0.049875  0.047531  0.759351   0.047531\n",
              "2011-01-05  0.047796  0.048863  0.045779  0.052297  0.448151   0.052297\n",
              "2011-01-06  0.047716  0.051318  0.050574  0.049212  0.380915   0.049212\n",
              "2011-01-07  0.049795  0.048176  0.053332  0.048481  0.782786   0.048481\n",
              "2011-01-10  0.043478  0.045616  0.047657  0.046879  0.436505   0.046879\n",
              "2011-01-11  0.044898  0.047073  0.048416  0.046207  0.269383   0.046207\n",
              "2011-01-12  0.043658  0.047260  0.048297  0.045693  0.225653   0.045693\n",
              "2011-01-13  0.045797  0.047697  0.044780  0.048560  0.433983   0.048560\n",
              "2011-01-14  0.050775  0.050632  0.048576  0.054926  0.508943   0.054926"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-345f209c-8a1d-4ef7-b4cc-4155aede4a95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.042911</td>\n",
              "      <td>0.040324</td>\n",
              "      <td>0.045970</td>\n",
              "      <td>0.791512</td>\n",
              "      <td>0.045970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>0.048296</td>\n",
              "      <td>0.048259</td>\n",
              "      <td>0.049875</td>\n",
              "      <td>0.047531</td>\n",
              "      <td>0.759351</td>\n",
              "      <td>0.047531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>0.047796</td>\n",
              "      <td>0.048863</td>\n",
              "      <td>0.045779</td>\n",
              "      <td>0.052297</td>\n",
              "      <td>0.448151</td>\n",
              "      <td>0.052297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>0.047716</td>\n",
              "      <td>0.051318</td>\n",
              "      <td>0.050574</td>\n",
              "      <td>0.049212</td>\n",
              "      <td>0.380915</td>\n",
              "      <td>0.049212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>0.049795</td>\n",
              "      <td>0.048176</td>\n",
              "      <td>0.053332</td>\n",
              "      <td>0.048481</td>\n",
              "      <td>0.782786</td>\n",
              "      <td>0.048481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.045616</td>\n",
              "      <td>0.047657</td>\n",
              "      <td>0.046879</td>\n",
              "      <td>0.436505</td>\n",
              "      <td>0.046879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.047073</td>\n",
              "      <td>0.048416</td>\n",
              "      <td>0.046207</td>\n",
              "      <td>0.269383</td>\n",
              "      <td>0.046207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>0.043658</td>\n",
              "      <td>0.047260</td>\n",
              "      <td>0.048297</td>\n",
              "      <td>0.045693</td>\n",
              "      <td>0.225653</td>\n",
              "      <td>0.045693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>0.045797</td>\n",
              "      <td>0.047697</td>\n",
              "      <td>0.044780</td>\n",
              "      <td>0.048560</td>\n",
              "      <td>0.433983</td>\n",
              "      <td>0.048560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>0.050775</td>\n",
              "      <td>0.050632</td>\n",
              "      <td>0.048576</td>\n",
              "      <td>0.054926</td>\n",
              "      <td>0.508943</td>\n",
              "      <td>0.054926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-345f209c-8a1d-4ef7-b4cc-4155aede4a95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-345f209c-8a1d-4ef7-b4cc-4155aede4a95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-345f209c-8a1d-4ef7-b4cc-4155aede4a95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **MaxAbs Scaling**"
      ],
      "metadata": {
        "id": "gdfJCDyLSjlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maxAbs_scale(data):\n",
        "    workdata4 = data.copy()\n",
        "    col = []\n",
        "    for col_name in workdata4.columns:\n",
        "      if workdata4[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      maxAbsScaling = MaxAbsScaler().fit(workdata4[[i]])\n",
        "      workdata4[i] = maxAbsScaling.transform(workdata4[[i]])\n",
        "    return workdata4"
      ],
      "metadata": {
        "id": "DnUv-SUkZhUd"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxAbs_Stock_Data = maxAbs_scale(StockData)\n",
        "maxAbs_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "dklPlovhZ4co",
        "outputId": "4ff66f1e-c167-4952-99a2-661555bd1c6d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                High       Low      Open     Close    Volume  Adj Close\n",
              "Date                                                                   \n",
              "2011-01-03  0.049297  0.049018  0.048443  0.049370  0.220906   0.049370\n",
              "2011-01-04  0.049747  0.049713  0.049720  0.049582  0.208493   0.049582\n",
              "2011-01-05  0.049681  0.049792  0.049172  0.050228  0.141658   0.050228\n",
              "2011-01-06  0.049670  0.050111  0.049813  0.049810  0.131751   0.049810\n",
              "2011-01-07  0.049946  0.049703  0.050182  0.049710  0.216361   0.049710\n",
              "2011-01-10  0.049108  0.049370  0.049423  0.049493  0.139880   0.049493\n",
              "2011-01-11  0.049297  0.049559  0.049525  0.049402  0.116606   0.049402\n",
              "2011-01-12  0.049132  0.049584  0.049509  0.049333  0.111008   0.049333\n",
              "2011-01-13  0.049416  0.049640  0.049038  0.049721  0.139512   0.049721\n",
              "2011-01-14  0.050076  0.050022  0.049546  0.050584  0.151768   0.050584"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66ba80a9-3493-426b-8584-68213c1986f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>0.049297</td>\n",
              "      <td>0.049018</td>\n",
              "      <td>0.048443</td>\n",
              "      <td>0.049370</td>\n",
              "      <td>0.220906</td>\n",
              "      <td>0.049370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>0.049747</td>\n",
              "      <td>0.049713</td>\n",
              "      <td>0.049720</td>\n",
              "      <td>0.049582</td>\n",
              "      <td>0.208493</td>\n",
              "      <td>0.049582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>0.049681</td>\n",
              "      <td>0.049792</td>\n",
              "      <td>0.049172</td>\n",
              "      <td>0.050228</td>\n",
              "      <td>0.141658</td>\n",
              "      <td>0.050228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>0.049670</td>\n",
              "      <td>0.050111</td>\n",
              "      <td>0.049813</td>\n",
              "      <td>0.049810</td>\n",
              "      <td>0.131751</td>\n",
              "      <td>0.049810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>0.049946</td>\n",
              "      <td>0.049703</td>\n",
              "      <td>0.050182</td>\n",
              "      <td>0.049710</td>\n",
              "      <td>0.216361</td>\n",
              "      <td>0.049710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>0.049108</td>\n",
              "      <td>0.049370</td>\n",
              "      <td>0.049423</td>\n",
              "      <td>0.049493</td>\n",
              "      <td>0.139880</td>\n",
              "      <td>0.049493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>0.049297</td>\n",
              "      <td>0.049559</td>\n",
              "      <td>0.049525</td>\n",
              "      <td>0.049402</td>\n",
              "      <td>0.116606</td>\n",
              "      <td>0.049402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>0.049132</td>\n",
              "      <td>0.049584</td>\n",
              "      <td>0.049509</td>\n",
              "      <td>0.049333</td>\n",
              "      <td>0.111008</td>\n",
              "      <td>0.049333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>0.049416</td>\n",
              "      <td>0.049640</td>\n",
              "      <td>0.049038</td>\n",
              "      <td>0.049721</td>\n",
              "      <td>0.139512</td>\n",
              "      <td>0.049721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>0.050076</td>\n",
              "      <td>0.050022</td>\n",
              "      <td>0.049546</td>\n",
              "      <td>0.050584</td>\n",
              "      <td>0.151768</td>\n",
              "      <td>0.050584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66ba80a9-3493-426b-8584-68213c1986f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66ba80a9-3493-426b-8584-68213c1986f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66ba80a9-3493-426b-8584-68213c1986f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Robust Scaling**"
      ],
      "metadata": {
        "id": "zJCTYp7ZSmL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def robust_scale(data):\n",
        "    workdata5 = data.copy()\n",
        "    col = []\n",
        "    for col_name in workdata5.columns:\n",
        "      if workdata5[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      robustScaling = RobustScaler().fit(workdata5[[i]])\n",
        "      workdata5[i] = robustScaling.transform(workdata5[[i]])\n",
        "    return workdata5"
      ],
      "metadata": {
        "id": "lMsXTkGYaIBf"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "robust_Stock_Data = robust_scale(StockData)\n",
        "robust_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "f1p_WjBlaPKx",
        "outputId": "6a3a4136-527f-4c8e-f0f6-62c236c25924"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                High       Low      Open     Close    Volume  Adj Close\n",
              "Date                                                                   \n",
              "2011-01-03 -0.364722 -0.367270 -0.366510 -0.365845  0.776161  -0.365845\n",
              "2011-01-04 -0.363585 -0.365523 -0.363297 -0.365314  0.639495  -0.365314\n",
              "2011-01-05 -0.363752 -0.365326 -0.364675 -0.363693 -0.096296  -0.363693\n",
              "2011-01-06 -0.363779 -0.364524 -0.363062 -0.364742 -0.205364  -0.364742\n",
              "2011-01-07 -0.363084 -0.365550 -0.362135 -0.364991  0.726120  -0.364991\n",
              "2011-01-10 -0.365197 -0.366386 -0.364043 -0.365536 -0.115865  -0.365536\n",
              "2011-01-11 -0.364722 -0.365911 -0.363788 -0.365764 -0.372092  -0.365764\n",
              "2011-01-12 -0.365136 -0.365850 -0.363828 -0.365939 -0.433720  -0.365939\n",
              "2011-01-13 -0.364421 -0.365707 -0.365011 -0.364964 -0.119925  -0.364964\n",
              "2011-01-14 -0.362756 -0.364749 -0.363734 -0.362798  0.015008  -0.362798"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-536d5dd3-0e17-4769-93df-fa6c8865169b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>-0.364722</td>\n",
              "      <td>-0.367270</td>\n",
              "      <td>-0.366510</td>\n",
              "      <td>-0.365845</td>\n",
              "      <td>0.776161</td>\n",
              "      <td>-0.365845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>-0.363585</td>\n",
              "      <td>-0.365523</td>\n",
              "      <td>-0.363297</td>\n",
              "      <td>-0.365314</td>\n",
              "      <td>0.639495</td>\n",
              "      <td>-0.365314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>-0.363752</td>\n",
              "      <td>-0.365326</td>\n",
              "      <td>-0.364675</td>\n",
              "      <td>-0.363693</td>\n",
              "      <td>-0.096296</td>\n",
              "      <td>-0.363693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>-0.363779</td>\n",
              "      <td>-0.364524</td>\n",
              "      <td>-0.363062</td>\n",
              "      <td>-0.364742</td>\n",
              "      <td>-0.205364</td>\n",
              "      <td>-0.364742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>-0.363084</td>\n",
              "      <td>-0.365550</td>\n",
              "      <td>-0.362135</td>\n",
              "      <td>-0.364991</td>\n",
              "      <td>0.726120</td>\n",
              "      <td>-0.364991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>-0.365197</td>\n",
              "      <td>-0.366386</td>\n",
              "      <td>-0.364043</td>\n",
              "      <td>-0.365536</td>\n",
              "      <td>-0.115865</td>\n",
              "      <td>-0.365536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>-0.364722</td>\n",
              "      <td>-0.365911</td>\n",
              "      <td>-0.363788</td>\n",
              "      <td>-0.365764</td>\n",
              "      <td>-0.372092</td>\n",
              "      <td>-0.365764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>-0.365136</td>\n",
              "      <td>-0.365850</td>\n",
              "      <td>-0.363828</td>\n",
              "      <td>-0.365939</td>\n",
              "      <td>-0.433720</td>\n",
              "      <td>-0.365939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>-0.364421</td>\n",
              "      <td>-0.365707</td>\n",
              "      <td>-0.365011</td>\n",
              "      <td>-0.364964</td>\n",
              "      <td>-0.119925</td>\n",
              "      <td>-0.364964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>-0.362756</td>\n",
              "      <td>-0.364749</td>\n",
              "      <td>-0.363734</td>\n",
              "      <td>-0.362798</td>\n",
              "      <td>0.015008</td>\n",
              "      <td>-0.362798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-536d5dd3-0e17-4769-93df-fa6c8865169b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-536d5dd3-0e17-4769-93df-fa6c8865169b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-536d5dd3-0e17-4769-93df-fa6c8865169b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Normalizer**"
      ],
      "metadata": {
        "id": "gMVmtLD9fdAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    workdata6 = data.copy()\n",
        "    col = []\n",
        "    for col_name in workdata6.columns:\n",
        "      if workdata6[col_name].dtype=='object':\n",
        "        pass\n",
        "      else: \n",
        "          col.append(col_name)\n",
        "    for i in col:\n",
        "      normal = Normalizer().fit(workdata6[[i]])\n",
        "      workdata6[i] = normal.transform(workdata6[[i]])\n",
        "    return workdata6"
      ],
      "metadata": {
        "id": "sg0OjPehfaoX"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_Stock_Data = normalize(StockData)\n",
        "normalized_Stock_Data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "RrVAqNPGgApr",
        "outputId": "ccdf1c90-5ed4-4973-e2fb-cd52e3f2babf"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            High  Low  Open  Close  Volume  Adj Close\n",
              "Date                                                 \n",
              "2011-01-03   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-04   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-05   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-06   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-07   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-10   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-11   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-12   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-13   1.0  1.0   1.0    1.0     1.0        1.0\n",
              "2011-01-14   1.0  1.0   1.0    1.0     1.0        1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3095738-0f0a-4ce8-a7c5-e685b7ea9448\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3095738-0f0a-4ce8-a7c5-e685b7ea9448')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3095738-0f0a-4ce8-a7c5-e685b7ea9448 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3095738-0f0a-4ce8-a7c5-e685b7ea9448');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "StockData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Z2yrM3-ggZZy",
        "outputId": "5b99bb82-4f87-4e8d-d5ca-b207ea20fad0"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  High         Low        Open       Close     Volume  \\\n",
              "Date                                                                    \n",
              "2011-01-03    9.300000    9.060500    9.068500    9.211000  106628000   \n",
              "2011-01-04    9.385000    9.189000    9.307500    9.250500  100636000   \n",
              "2011-01-05    9.372500    9.203500    9.205000    9.371000   68376000   \n",
              "2011-01-06    9.370500    9.262500    9.325000    9.293000   63594000   \n",
              "2011-01-07    9.422500    9.187000    9.394000    9.274500  104434000   \n",
              "...                ...         ...         ...         ...        ...   \n",
              "2021-12-27  172.942993  169.215500  171.037003  169.669495   58688000   \n",
              "2021-12-28  172.175995  169.135498  170.182495  170.660995   54638000   \n",
              "2021-12-29  171.212006  168.600494  170.839996  169.201004   35754000   \n",
              "2021-12-30  170.888000  168.524002  169.699997  168.644501   37584000   \n",
              "2021-12-31  169.350006  166.558502  168.955994  166.716995   47830000   \n",
              "\n",
              "             Adj Close  \n",
              "Date                    \n",
              "2011-01-03    9.211000  \n",
              "2011-01-04    9.250500  \n",
              "2011-01-05    9.371000  \n",
              "2011-01-06    9.293000  \n",
              "2011-01-07    9.274500  \n",
              "...                ...  \n",
              "2021-12-27  169.669495  \n",
              "2021-12-28  170.660995  \n",
              "2021-12-29  169.201004  \n",
              "2021-12-30  168.644501  \n",
              "2021-12-31  166.716995  \n",
              "\n",
              "[2769 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b04c168-fa47-431e-8589-3052390dcc17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-03</th>\n",
              "      <td>9.300000</td>\n",
              "      <td>9.060500</td>\n",
              "      <td>9.068500</td>\n",
              "      <td>9.211000</td>\n",
              "      <td>106628000</td>\n",
              "      <td>9.211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-04</th>\n",
              "      <td>9.385000</td>\n",
              "      <td>9.189000</td>\n",
              "      <td>9.307500</td>\n",
              "      <td>9.250500</td>\n",
              "      <td>100636000</td>\n",
              "      <td>9.250500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-05</th>\n",
              "      <td>9.372500</td>\n",
              "      <td>9.203500</td>\n",
              "      <td>9.205000</td>\n",
              "      <td>9.371000</td>\n",
              "      <td>68376000</td>\n",
              "      <td>9.371000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-06</th>\n",
              "      <td>9.370500</td>\n",
              "      <td>9.262500</td>\n",
              "      <td>9.325000</td>\n",
              "      <td>9.293000</td>\n",
              "      <td>63594000</td>\n",
              "      <td>9.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-07</th>\n",
              "      <td>9.422500</td>\n",
              "      <td>9.187000</td>\n",
              "      <td>9.394000</td>\n",
              "      <td>9.274500</td>\n",
              "      <td>104434000</td>\n",
              "      <td>9.274500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-27</th>\n",
              "      <td>172.942993</td>\n",
              "      <td>169.215500</td>\n",
              "      <td>171.037003</td>\n",
              "      <td>169.669495</td>\n",
              "      <td>58688000</td>\n",
              "      <td>169.669495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-28</th>\n",
              "      <td>172.175995</td>\n",
              "      <td>169.135498</td>\n",
              "      <td>170.182495</td>\n",
              "      <td>170.660995</td>\n",
              "      <td>54638000</td>\n",
              "      <td>170.660995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-29</th>\n",
              "      <td>171.212006</td>\n",
              "      <td>168.600494</td>\n",
              "      <td>170.839996</td>\n",
              "      <td>169.201004</td>\n",
              "      <td>35754000</td>\n",
              "      <td>169.201004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-30</th>\n",
              "      <td>170.888000</td>\n",
              "      <td>168.524002</td>\n",
              "      <td>169.699997</td>\n",
              "      <td>168.644501</td>\n",
              "      <td>37584000</td>\n",
              "      <td>168.644501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>169.350006</td>\n",
              "      <td>166.558502</td>\n",
              "      <td>168.955994</td>\n",
              "      <td>166.716995</td>\n",
              "      <td>47830000</td>\n",
              "      <td>166.716995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2769 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b04c168-fa47-431e-8589-3052390dcc17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b04c168-fa47-431e-8589-3052390dcc17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b04c168-fa47-431e-8589-3052390dcc17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML models and fitting**"
      ],
      "metadata": {
        "id": "bKAcvOBuhuVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM**"
      ],
      "metadata": {
        "id": "GjGR9xYth1PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_svm():\n",
        "  # split Standardized dataset\n",
        "  X_train1, X_test1, Y_train1, Y_test1 = split(standard_Stock_Data)\n",
        "\n",
        "  # split MinMax dataset\n",
        "  X_train2, X_test2, Y_train2, Y_test2, = split(minMax_Stock_Data)\n",
        "\n",
        "  # split Binirized dataset\n",
        "  X_train3, X_test3, Y_train3, Y_test3,= split(binirized_Stock_Data)\n",
        "\n",
        "  # split Quant Scale dataset\n",
        "  X_train4, X_test4, Y_train4, Y_test4, = split(Quant_Stock_Data)\n",
        "\n",
        "  # split Robust Scale dataset\n",
        "  X_train5, X_test5, Y_train5, Y_test5 = split(robust_Stock_Data)\n",
        "\n",
        "  # split Normalized dataset\n",
        "  X_train6, X_test6, Y_train6, Y_test6 = split(normalized_Stock_Data)\n",
        "\n",
        "  # split maxAbs dataset\n",
        "  X_train7, X_test7, Y_train7, Y_test7= split(maxAbs_Stock_Data)\n",
        "\n",
        "  #initiate regressors \n",
        "  stan_classifier = svm.LinearSVR()\n",
        "  minMax_classifier = svm.LinearSVR()\n",
        "  bin_classifier = svm.LinearSVR()\n",
        "  quant_classifier = svm.LinearSVR()\n",
        "  rob_classifier = svm.LinearSVR()\n",
        "  nom_classifier = svm.LinearSVR()\n",
        "  maxabs_classifier = svm.LinearSVR()\n",
        "\n",
        "  # fitting models\n",
        "  stan_classifier.fit(X_train1,Y_train1)\n",
        "  minMax_classifier.fit(X_train2,Y_train2)\n",
        "  bin_classifier.fit(X_train3,Y_train3)\n",
        "  quant_classifier.fit(X_train4,Y_train4)\n",
        "  rob_classifier.fit(X_train5,Y_train5)\n",
        "  nom_classifier.fit(X_train6,Y_train6)\n",
        "  maxabs_classifier.fit(X_train7,Y_train7)\n",
        "\n",
        "  # predict\n",
        "  Y_predict1 = stan_classifier.predict(X_test1)\n",
        "  Y_predict2 = minMax_classifier.predict(X_test2)\n",
        "  Y_predict3 = bin_classifier.predict(X_test3)\n",
        "  Y_predict4 = quant_classifier.predict(X_test4)\n",
        "  Y_predict5 = rob_classifier.predict(X_test5)\n",
        "  Y_predict6 = nom_classifier.predict(X_test6)\n",
        "  Y_predict7 = maxabs_classifier.predict(X_test7)\n",
        "  # check accuracy\n",
        "  accuracy_stan = stan_classifier.score(X_test1, Y_test1)\n",
        "  accuracy_minmax = minMax_classifier.score(X_test2, Y_test2)\n",
        "  accuracy_bin = bin_classifier.score(X_test3, Y_test3)\n",
        "  accuracy_quant = quant_classifier.score(X_test4, Y_test4)\n",
        "  accuracy_rob = rob_classifier.score(X_test5, Y_test5)\n",
        "  accuracy_nom = nom_classifier.score(X_test6, Y_test6)\n",
        "  accuracy_maxabs = maxabs_classifier.score(X_test7, Y_test7)\n",
        "\n",
        "  print(\"ACCURACY SVM\")\n",
        "  print(\"SVR Accuracy before scaling :\", accuracy_b4, \n",
        "        \"\\n SVR Accuracy after Standardization :\", accuracy_stan, \n",
        "        \"\\n SVR Accuracy after MinMax Scaling :\", accuracy_minmax, \n",
        "        \"\\n SVR Accuracy after Binirization :\", accuracy_bin,\n",
        "        \"\\n SVR Accuracy after Quantile Scaling :\", accuracy_quant,\n",
        "        \"\\n SVR Accuracy after Robust Scaling :\", accuracy_rob,\n",
        "        \"\\n SVR Accuracy after Normalization :\", accuracy_nom,\n",
        "        \"\\n SVR Accuracy after MaxAbs Scaling :\", accuracy_maxabs, \"\\n\")\n",
        "  \n",
        "  \n",
        "  # check R2 score:\n",
        "  r2_1 = r2_score(Y_test1, Y_predict1)\n",
        "  r2_2 = r2_score(Y_test2, Y_predict2)\n",
        "  r2_3 = r2_score(Y_test3, Y_predict3)\n",
        "  r2_4 = r2_score(Y_test4, Y_predict4)\n",
        "  r2_5 = r2_score(Y_test5, Y_predict5)\n",
        "  r2_6 = r2_score(Y_test6, Y_predict6)\n",
        "  r2_7 = r2_score(Y_test7, Y_predict7)\n",
        "  print(\"R2 SVM\")\n",
        "  print(\"SVR R2 before scaling :\", r2_b4, \n",
        "        \"\\n SVR R2 after Standardization :\", r2_1, \n",
        "        \"\\n SVR R2 after MinMax Scaling :\", r2_2, \n",
        "        \"\\n SVR R2 after Binirization :\", r2_3,\n",
        "        \"\\n SVR R2 after Quantile Scaling :\", r2_4,\n",
        "        \"\\n SVR R2 after Robust Scaling :\", r2_5,\n",
        "        \"\\n SVR R2 after Normalization :\", r2_6,\n",
        "        \"\\n SVR R2 after MaxAbs Scaling :\", r2_7, \"\\n\")\n",
        "  \n",
        "  # Check Root Mean Squared Error\n",
        "  \n",
        "  rmse_1 = mean_squared_error(Y_test1, Y_predict1, squared=False)\n",
        "  rmse_2 = mean_squared_error(Y_test2, Y_predict2, squared=False)\n",
        "  rmse_3 = mean_squared_error(Y_test3, Y_predict3, squared=False)\n",
        "  rmse_4 = mean_squared_error(Y_test4, Y_predict4, squared=False)\n",
        "  rmse_5 = mean_squared_error(Y_test5, Y_predict5, squared=False)\n",
        "  rmse_6 = mean_squared_error(Y_test6, Y_predict6, squared=False)\n",
        "  rmse_7 = mean_squared_error(Y_test7, Y_predict7, squared=False)\n",
        "  print(\"RMSE SVM\")\n",
        "  print(\"SVR RMSE before scaling :\", rmse_b4, \n",
        "        \"\\n SVR RMSE after Standardization :\", rmse_1, \n",
        "        \"\\n SVR RMSE after MinMax Scaling :\", rmse_2, \n",
        "        \"\\n SVR RMSE after Binirization :\", rmse_3,\n",
        "        \"\\n SVR RMSE after Quantile Scaling :\", rmse_4,\n",
        "        \"\\n SVR RMSE after Robust Scaling :\", rmse_5,\n",
        "        \"\\n SVR RMSE after Normalization :\", rmse_6,\n",
        "        \"\\n SVR RMSE after MaxAbs Scaling :\", rmse_7, \"\\n\")\n",
        "  \n",
        "  # check Mean Absolute Percentage Error \n",
        "  mape_1 = mean_absolute_percentage_error(Y_test1, Y_predict1)\n",
        "  mape_2 = mean_absolute_percentage_error(Y_test2, Y_predict2)\n",
        "  mape_3 = mean_absolute_percentage_error(Y_test3, Y_predict3)\n",
        "  mape_4 = mean_absolute_percentage_error(Y_test4, Y_predict4)\n",
        "  mape_5 = mean_absolute_percentage_error(Y_test5, Y_predict5)\n",
        "  mape_6 = mean_absolute_percentage_error(Y_test6, Y_predict6)\n",
        "  mape_7 = mean_absolute_percentage_error(Y_test7, Y_predict7)\n",
        "  print(\"MAPE SVM\")\n",
        "  print(\"SVR MAPE before scaling :\", mape_b4, \n",
        "        \"\\n SVR MAPE after Standardization :\", mape_1, \n",
        "        \"\\n SVR MAPE after MinMax Scaling :\", mape_2, \n",
        "        \"\\n SVR MAPE after Binirization :\", mape_3,\n",
        "        \"\\n SVR MAPE after Quantile Scaling :\", mape_4,\n",
        "        \"\\n SVR MAPE after Robust Scaling :\", mape_5,\n",
        "        \"\\n SVR MAPE after Normalization :\", mape_6,\n",
        "        \"\\n SVR MAPE after MaxAbs Scaling :\", mape_7, \"\\n\")\n",
        "\n",
        "\n",
        "  return \n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "9HAqXlGdh0Uv"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_svm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXJeYWN3qETg",
        "outputId": "ffa6e3ae-1b0f-4dc8-e80b-2a66f2ffd775"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY SVM\n",
            "SVR Accuracy before scaling : 0.9999999417807311 \n",
            " SVR Accuracy after Standardization : 0.9999999758126394 \n",
            " SVR Accuracy after MinMax Scaling : 0.9999973269697086 \n",
            " SVR Accuracy after Binirization : 1.0 \n",
            " SVR Accuracy after Quantile Scaling : 0.9999985025160025 \n",
            " SVR Accuracy after Robust Scaling : 0.9999997824002838 \n",
            " SVR Accuracy after Normalization : 1.0 \n",
            " SVR Accuracy after MaxAbs Scaling : 0.9999968359517241 \n",
            "\n",
            "R2 SVM\n",
            "SVR R2 before scaling : 0.9999999417807311 \n",
            " SVR R2 after Standardization : 0.9999999758126394 \n",
            " SVR R2 after MinMax Scaling : 0.9999973269697086 \n",
            " SVR R2 after Binirization : 1.0 \n",
            " SVR R2 after Quantile Scaling : 0.9999985025160025 \n",
            " SVR R2 after Robust Scaling : 0.9999997824002838 \n",
            " SVR R2 after Normalization : 1.0 \n",
            " SVR R2 after MaxAbs Scaling : 0.9999968359517241 \n",
            "\n",
            "RMSE SVM\n",
            "SVR RMSE before scaling : 0.01260930226452146 \n",
            " SVR RMSE after Standardization : 0.00015508796308448276 \n",
            " SVR RMSE after MinMax Scaling : 0.0004785947049075082 \n",
            " SVR RMSE after Binirization : 0.0 \n",
            " SVR RMSE after Quantile Scaling : 0.000345742361091247 \n",
            " SVR RMSE after Robust Scaling : 0.000327952574177333 \n",
            " SVR RMSE after Normalization : 0.0 \n",
            " SVR RMSE after MaxAbs Scaling : 0.0004982373343928496 \n",
            "\n",
            "MAPE SVM\n",
            "SVR MAPE before scaling : 0.00012099855746256524 \n",
            " SVR MAPE after Standardization : 0.00022676998819584827 \n",
            " SVR MAPE after MinMax Scaling : 243240493.87418133 \n",
            " SVR MAPE after Binirization : 0.0 \n",
            " SVR MAPE after Quantile Scaling : 852188880.9953576 \n",
            " SVR MAPE after Robust Scaling : 367472543.37009203 \n",
            " SVR MAPE after Normalization : 0.0 \n",
            " SVR MAPE after MaxAbs Scaling : 0.0008933724923603212 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Linear Regression**"
      ],
      "metadata": {
        "id": "mztsD8CJzHAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LinearRegression(random_state=0)\n",
        "def scaled_linR():\n",
        "  # split Standardized dataset\n",
        "  X_train1, X_test1, Y_train1, Y_test1 = split(standard_Stock_Data)\n",
        "\n",
        "  # split MinMax dataset\n",
        "  X_train2, X_test2, Y_train2, Y_test2, = split(minMax_Stock_Data)\n",
        "\n",
        "  # split Binirized dataset\n",
        "  X_train3, X_test3, Y_train3, Y_test3,= split(binirized_Stock_Data)\n",
        "\n",
        "  # split Quant Scale dataset\n",
        "  X_train4, X_test4, Y_train4, Y_test4, = split(Quant_Stock_Data)\n",
        "\n",
        "  # split Robust Scale dataset\n",
        "  X_train5, X_test5, Y_train5, Y_test5 = split(robust_Stock_Data)\n",
        "\n",
        "  # split Normalized dataset\n",
        "  X_train6, X_test6, Y_train6, Y_test6 = split(normalized_Stock_Data)\n",
        "\n",
        "  # split maxAbs dataset\n",
        "  X_train7, X_test7, Y_train7, Y_test7= split(maxAbs_Stock_Data)\n",
        "\n",
        "  #initiate regressors \n",
        "  stan_classifier = LinearRegression()\n",
        "  minMax_classifier = LinearRegression()\n",
        "  bin_classifier = LinearRegression()\n",
        "  quant_classifier = LinearRegression()\n",
        "  rob_classifier = LinearRegression()\n",
        "  nom_classifier = LinearRegression()\n",
        "  maxabs_classifier = LinearRegression()\n",
        "\n",
        "  # fitting models\n",
        "  stan_classifier.fit(X_train1,Y_train1)\n",
        "  minMax_classifier.fit(X_train2,Y_train2)\n",
        "  bin_classifier.fit(X_train3,Y_train3)\n",
        "  quant_classifier.fit(X_train4,Y_train4)\n",
        "  rob_classifier.fit(X_train5,Y_train5)\n",
        "  nom_classifier.fit(X_train6,Y_train6)\n",
        "  maxabs_classifier.fit(X_train7,Y_train7)\n",
        "\n",
        "  # predict\n",
        "  Y_predict1 = stan_classifier.predict(X_test1)\n",
        "  Y_predict2 = minMax_classifier.predict(X_test2)\n",
        "  Y_predict3 = bin_classifier.predict(X_test3)\n",
        "  Y_predict4 = quant_classifier.predict(X_test4)\n",
        "  Y_predict5 = rob_classifier.predict(X_test5)\n",
        "  Y_predict6 = nom_classifier.predict(X_test6)\n",
        "  Y_predict7 = maxabs_classifier.predict(X_test7)\n",
        "\n",
        "  # check accuracy\n",
        "  accuracy_stan = stan_classifier.score(X_test1, Y_test1)\n",
        "  accuracy_minmax = minMax_classifier.score(X_test2, Y_test2)\n",
        "  accuracy_bin = bin_classifier.score(X_test3, Y_test3)\n",
        "  accuracy_quant = quant_classifier.score(X_test4, Y_test4)\n",
        "  accuracy_rob = rob_classifier.score(X_test5, Y_test5)\n",
        "  accuracy_nom = nom_classifier.score(X_test6, Y_test6)\n",
        "  accuracy_maxabs = maxabs_classifier.score(X_test7, Y_test7)\n",
        "\n",
        "  print(\"ACCURACY LinearRegression\")\n",
        "  print(\"LinearRegression Accuracy before scaling :\", accuracy_b4_lin, \n",
        "        \"\\n LinearRegression Accuracy after Standardization :\", accuracy_stan, \n",
        "        \"\\n LinearRegression Accuracy after MinMax Scaling :\", accuracy_minmax, \n",
        "        \"\\n LinearRegression Accuracy after Binirization :\", accuracy_bin,\n",
        "        \"\\n LinearRegression Accuracy after Quantile Scaling :\", accuracy_quant,\n",
        "        \"\\n LinearRegression Accuracy after Robust Scaling :\", accuracy_rob,\n",
        "        \"\\n LinearRegression Accuracy after Normalization :\", accuracy_nom,\n",
        "        \"\\n LinearRegression Accuracy after MaxAbs Scaling :\", accuracy_maxabs, \"\\n\")\n",
        "  \n",
        "  \n",
        "  # check R2 score:\n",
        "  r2_1 = r2_score(Y_test1, Y_predict1)\n",
        "  r2_2 = r2_score(Y_test2, Y_predict2)\n",
        "  r2_3 = r2_score(Y_test3, Y_predict3)\n",
        "  r2_4 = r2_score(Y_test4, Y_predict4)\n",
        "  r2_5 = r2_score(Y_test5, Y_predict5)\n",
        "  r2_6 = r2_score(Y_test6, Y_predict6)\n",
        "  r2_7 = r2_score(Y_test7, Y_predict7)\n",
        "  print(\"R2 LinearRegression\")\n",
        "  print(\"LinearRegression R2 before scaling :\", r2_b4_lin, \n",
        "        \"\\n LinearRegression R2 after Standardization :\", r2_1, \n",
        "        \"\\n LinearRegression R2 after MinMax Scaling :\", r2_2, \n",
        "        \"\\n LinearRegression R2 after Binirization :\", r2_3,\n",
        "        \"\\n LinearRegression R2 after Quantile Scaling :\", r2_4,\n",
        "        \"\\n LinearRegression R2 after Robust Scaling :\", r2_5,\n",
        "        \"\\n LinearRegression R2 after Normalization :\", r2_6,\n",
        "        \"\\n LinearRegression R2 after MaxAbs Scaling :\", r2_7, \"\\n\")\n",
        "  \n",
        "  # Check Root Mean Squared Error\n",
        "  \n",
        "  rmse_1 = mean_squared_error(Y_test1, Y_predict1, squared=False)\n",
        "  rmse_2 = mean_squared_error(Y_test2, Y_predict2, squared=False)\n",
        "  rmse_3 = mean_squared_error(Y_test3, Y_predict3, squared=False)\n",
        "  rmse_4 = mean_squared_error(Y_test4, Y_predict4, squared=False)\n",
        "  rmse_5 = mean_squared_error(Y_test5, Y_predict5, squared=False)\n",
        "  rmse_6 = mean_squared_error(Y_test6, Y_predict6, squared=False)\n",
        "  rmse_7 = mean_squared_error(Y_test7, Y_predict7, squared=False)\n",
        "  print(\"RMSE LinearRegression\")\n",
        "  print(\"LinearRegression RMSE before scaling :\", rmse_b4_lin, \n",
        "        \"\\n LinearRegression RMSE after Standardization :\", rmse_1, \n",
        "        \"\\n LinearRegression RMSE after MinMax Scaling :\", rmse_2, \n",
        "        \"\\n LinearRegression RMSE after Binirization :\", rmse_3,\n",
        "        \"\\n LinearRegression RMSE after Quantile Scaling :\", rmse_4,\n",
        "        \"\\n LinearRegression RMSE after Robust Scaling :\", rmse_5,\n",
        "        \"\\n LinearRegression RMSE after Normalization :\", rmse_6,\n",
        "        \"\\n LinearRegression RMSE after MaxAbs Scaling :\", rmse_7, \"\\n\")\n",
        "  \n",
        "  # check Mean Absolute Percentage Error \n",
        "  mape_1 = mean_absolute_percentage_error(Y_test1, Y_predict1)\n",
        "  mape_2 = mean_absolute_percentage_error(Y_test2, Y_predict2)\n",
        "  mape_3 = mean_absolute_percentage_error(Y_test3, Y_predict3)\n",
        "  mape_4 = mean_absolute_percentage_error(Y_test4, Y_predict4)\n",
        "  mape_5 = mean_absolute_percentage_error(Y_test5, Y_predict5)\n",
        "  mape_6 = mean_absolute_percentage_error(Y_test6, Y_predict6)\n",
        "  mape_7 = mean_absolute_percentage_error(Y_test7, Y_predict7)\n",
        "  print(\"MAPE LinearRegression\")\n",
        "  print(\"LinearRegression MAPE before scaling :\", mape_b4_lin, \n",
        "        \"\\n LinearRegression MAPE after Standardization :\", mape_1, \n",
        "        \"\\n LinearRegression MAPE after MinMax Scaling :\", mape_2, \n",
        "        \"\\n LinearRegression MAPE after Binirization :\", mape_3,\n",
        "        \"\\n LinearRegression MAPE after Quantile Scaling :\", mape_4,\n",
        "        \"\\n LinearRegression MAPE after Robust Scaling :\", mape_5,\n",
        "        \"\\n LinearRegression MAPE after Normalization :\", mape_6,\n",
        "        \"\\n LinearRegression MAPE after MaxAbs Scaling :\", mape_7, \"\\n\")\n",
        "\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "qpd-kbbtjJwG"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_linR()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ_Fyh4fz8Ff",
        "outputId": "ce0665e4-dd9e-4245-f888-b0fd5b2253ed"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY LinearRegression\n",
            "LinearRegression Accuracy before scaling : 1.0 \n",
            " LinearRegression Accuracy after Standardization : 1.0 \n",
            " LinearRegression Accuracy after MinMax Scaling : 1.0 \n",
            " LinearRegression Accuracy after Binirization : 1.0 \n",
            " LinearRegression Accuracy after Quantile Scaling : 1.0 \n",
            " LinearRegression Accuracy after Robust Scaling : 1.0 \n",
            " LinearRegression Accuracy after Normalization : 1.0 \n",
            " LinearRegression Accuracy after MaxAbs Scaling : 1.0 \n",
            "\n",
            "R2 LinearRegression\n",
            "LinearRegression R2 before scaling : 1.0 \n",
            " LinearRegression R2 after Standardization : 1.0 \n",
            " LinearRegression R2 after MinMax Scaling : 1.0 \n",
            " LinearRegression R2 after Binirization : 1.0 \n",
            " LinearRegression R2 after Quantile Scaling : 1.0 \n",
            " LinearRegression R2 after Robust Scaling : 1.0 \n",
            " LinearRegression R2 after Normalization : 1.0 \n",
            " LinearRegression R2 after MaxAbs Scaling : 1.0 \n",
            "\n",
            "RMSE LinearRegression\n",
            "LinearRegression RMSE before scaling : 7.032334375143089e-15 \n",
            " LinearRegression RMSE after Standardization : 1.6678297918878396e-16 \n",
            " LinearRegression RMSE after MinMax Scaling : 1.8695242445890674e-16 \n",
            " LinearRegression RMSE after Binirization : 0.0 \n",
            " LinearRegression RMSE after Quantile Scaling : 9.642815190317967e-17 \n",
            " LinearRegression RMSE after Robust Scaling : 3.275876037029302e-16 \n",
            " LinearRegression RMSE after Normalization : 0.0 \n",
            " LinearRegression RMSE after MaxAbs Scaling : 2.0867453723880154e-16 \n",
            "\n",
            "MAPE LinearRegression\n",
            "LinearRegression MAPE before scaling : 3.580171107965614e-17 \n",
            " LinearRegression MAPE after Standardization : 1.5830619547517475e-16 \n",
            " LinearRegression MAPE after MinMax Scaling : 0.00038445599233981635 \n",
            " LinearRegression MAPE after Binirization : 0.0 \n",
            " LinearRegression MAPE after Quantile Scaling : 0.00037472176143033887 \n",
            " LinearRegression MAPE after Robust Scaling : 0.00025851478160761034 \n",
            " LinearRegression MAPE after Normalization : 0.0 \n",
            " LinearRegression MAPE after MaxAbs Scaling : 1.22297131117618e-15 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM**"
      ],
      "metadata": {
        "id": "P5r0G3sJ6ed5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reshaped_split(dataset):\n",
        "\n",
        "  # In this, we select the set of attributes that directly affect the dependent variables (Close) in our dataset:\n",
        "  features =  ['High', 'Low', 'Open','Adj Close']\n",
        "\n",
        "  # Then split the data between y(dependent) and X(independent) variables:\n",
        "  y = dataset['Close']\n",
        "  x = dataset[features]\n",
        "\n",
        "  \n",
        "  # After that, we split our dataset into the training set and testing set in the ratios of 80:20:\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.7, random_state=1)\n",
        "\n",
        "  # reshape train and test data for LSTM (LSTM expects data to be threee dimentional)\n",
        "  # convert to numpy array\n",
        "  X_train, X_test, Y_train, Y_test = np.array(X_train), np.array(X_test), np.array(Y_train), np.array(Y_test)\n",
        "\n",
        "  # reshape the data\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
        "  # reshape the data \n",
        "  X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "GuEavqyj7qbs"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm(x_train, x_test, y_train, y_test):\n",
        "  # Build the Model\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units=50, return_sequences=True, input_shape = (x_train.shape[1], 1)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(units=50, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(units=50))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(units=1)) # prediction of the next closing price\n",
        "\n",
        "  # investigate loss functions and optimisers \n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  # train model\n",
        "  # feed the model 25 epochs and model will see 32 units of the batch size every time\n",
        "  model.fit(x_train, y_train, epochs=25, batch_size=32)\n",
        "\n",
        "  # get models predicted price values\n",
        "  predicted_prices = model.predict(x_test)\n",
        "\n",
        "  # evaluate model\n",
        "\n",
        "  # check accuracy, R2 score, Root Mean Squared Error, Mean Absolute Percentage Error \n",
        "  #accuracy_lstm = model.score(x_test, y_test)\n",
        "  r2_lstm = r2_score(y_test, predicted_prices)\n",
        "  rmse_lstm = mean_squared_error(y_test, predicted_prices, squared=False)\n",
        "  mape_lstm = mean_absolute_percentage_error(y_test, predicted_prices)\n",
        "  #\"ACCURACY of LSTM for scaling method: \", accuracy_lstm,\n",
        "  #print( \"\\n R2 of LSTM for scaling method: \", r2_lstm,\n",
        "        #\"\\n Root Mean Squared Error of LSTM for scaling method: \", rmse_lstm,\n",
        "        #\"\\n Mean Absolute Percentage Error of LSTM for scaling method: \", mape_lstm,\"\\n\")\n",
        "  return r2_lstm, rmse_lstm, mape_lstm\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "CXneI87i_-jN"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_lstm():\n",
        "\n",
        "  # split Standardized dataset\n",
        "  X_train1, X_test1, Y_train1, Y_test1 = reshaped_split(standard_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for Standardized dataset:\")\n",
        "  r2_lstm_std, rmse_lstm_std, mape_lstm_std = lstm(X_train1, X_test1, Y_train1, Y_test1)\n",
        "\n",
        "  # split MinMax dataset\n",
        "  X_train2, X_test2, Y_train2, Y_test2, = reshaped_split(minMax_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for MinMax dataset:\")\n",
        "  r2_lstm_min, rmse_lstm_min, mape_lstm_min = lstm(X_train2, X_test2, Y_train2, Y_test2)\n",
        "\n",
        "  # split Binirized dataset\n",
        "  X_train3, X_test3, Y_train3, Y_test3,= reshaped_split(binirized_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for Binirized dataset:\")\n",
        "  r2_lstm_bin, rmse_lstm_bin, mape_lstm_bin = lstm(X_train3, X_test3, Y_train3, Y_test3)\n",
        "\n",
        "  # split Quant Scale dataset\n",
        "  X_train4, X_test4, Y_train4, Y_test4, = reshaped_split(Quant_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for Quant Scale dataset:\")\n",
        "  r2_lstm_quant, rmse_lstm_quant, mape_lstm_quant = lstm(X_train4, X_test4, Y_train4, Y_test4)\n",
        "\n",
        "  # split Robust Scale dataset\n",
        "  X_train5, X_test5, Y_train5, Y_test5 = reshaped_split(robust_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for Robust Scale dataset:\")\n",
        "  r2_lstm_rob, rmse_lstm_rob, mape_lstm_rob = lstm(X_train5, X_test5, Y_train5, Y_test5)\n",
        "\n",
        "  # split Normalized dataset\n",
        "  X_train6, X_test6, Y_train6, Y_test6 = reshaped_split(normalized_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for Normalized dataset:\")\n",
        "  r2_lstm_nom, rmse_lstm_nom, mape_lstm_nom = lstm(X_train6, X_test6, Y_train6, Y_test6)\n",
        "\n",
        "  # split maxAbs dataset\n",
        "  X_train7, X_test7, Y_train7, Y_test7= reshaped_split(maxAbs_Stock_Data)\n",
        "  print(\"Evaluation of LSTM for maxAbs dataset:\")\n",
        "  r2_lstm_max, rmse_lstm_max, mape_lstm_max = lstm(X_train7, X_test7, Y_train7, Y_test7)\n",
        "\n",
        "  \n",
        "  # check R2 score:\n",
        "  print(\"R2 LSTM\")\n",
        "  print(\"LinearRegression R2 before scaling : nil\",  \n",
        "        \"\\n LinearRegression R2 after Standardization :\", r2_lstm_std, \n",
        "        \"\\n LinearRegression R2 after MinMax Scaling :\", r2_lstm_min, \n",
        "        \"\\n LinearRegression R2 after Binirization :\", r2_lstm_bin,\n",
        "        \"\\n LinearRegression R2 after Quantile Scaling :\", r2_lstm_quant,\n",
        "        \"\\n LinearRegression R2 after Robust Scaling :\", r2_lstm_rob,\n",
        "        \"\\n LinearRegression R2 after Normalization :\", r2_lstm_nom,\n",
        "        \"\\n LinearRegression R2 after MaxAbs Scaling :\", r2_lstm_max, \"\\n\")\n",
        "  \n",
        "  # Check Root Mean Squared Error\n",
        "  \n",
        "  print(\"RMSE LSTM\")\n",
        "  print(\"LinearRegression RMSE before scaling : nil\", \n",
        "        \"\\n LinearRegression RMSE after Standardization :\", rmse_lstm_std, \n",
        "        \"\\n LinearRegression RMSE after MinMax Scaling :\", rmse_lstm_min, \n",
        "        \"\\n LinearRegression RMSE after Binirization :\", rmse_lstm_bin,\n",
        "        \"\\n LinearRegression RMSE after Quantile Scaling :\", rmse_lstm_quant,\n",
        "        \"\\n LinearRegression RMSE after Robust Scaling :\", rmse_lstm_rob,\n",
        "        \"\\n LinearRegression RMSE after Normalization :\", rmse_lstm_nom,\n",
        "        \"\\n LinearRegression RMSE after MaxAbs Scaling :\", rmse_lstm_max, \"\\n\")\n",
        "  \n",
        "  # check Mean Absolute Percentage Error \n",
        "  print(\"MAPE LSTM\")\n",
        "  print(\"LinearRegression MAPE before scaling :nil\", \n",
        "        \"\\n LinearRegression MAPE after Standardization :\", mape_lstm_std, \n",
        "        \"\\n LinearRegression MAPE after MinMax Scaling :\", mape_lstm_min, \n",
        "        \"\\n LinearRegression MAPE after Binirization :\", mape_lstm_bin,\n",
        "        \"\\n LinearRegression MAPE after Quantile Scaling :\", mape_lstm_quant,\n",
        "        \"\\n LinearRegression MAPE after Robust Scaling :\", mape_lstm_rob,\n",
        "        \"\\n LinearRegression MAPE after Normalization :\", mape_lstm_nom,\n",
        "        \"\\n LinearRegression MAPE after MaxAbs Scaling :\", mape_lstm_max, \"\\n\")\n",
        "\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "FsshL9T87MwM"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lstm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88aZEh_OEbBN",
        "outputId": "889e9cd6-1101-446f-fea5-3e68aaafad2a"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation of LSTM for Standardized dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 7s 13ms/step - loss: 0.6776\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0493\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0181\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0132\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0149\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0147\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0142\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0139\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0129\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0114\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0111\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0116\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0114\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0117\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0089\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0101\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0096\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0108\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0100\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0102\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0124\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "61/61 [==============================] - 2s 4ms/step\n",
            "Evaluation of LSTM for MinMax dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 8s 12ms/step - loss: 0.0814\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0075\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0035\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0025\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0023\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0020\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0015\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0018\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0015\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0015\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0017\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0016\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0015\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0016\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0014\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0012\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0014\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0016\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0011\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0013\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0015\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0015\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0016\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0013\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0012\n",
            "61/61 [==============================] - 2s 4ms/step\n",
            "Evaluation of LSTM for Binirized dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 7s 13ms/step - loss: 0.4036\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0106\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0094\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0094\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0081\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0084\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0087\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0079\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0068\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0072\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0072\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0066\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0067\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0063\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0065\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0065\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0063\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0060\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0060\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0061\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0058\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0055\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0054\n",
            "61/61 [==============================] - 2s 5ms/step\n",
            "Evaluation of LSTM for Quant Scale dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 8s 14ms/step - loss: 0.1436\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0278\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0078\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0051\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0038\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0040\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0038\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0031\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0030\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0029\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0027\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0028\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0027\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0030\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0027\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0024\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0031\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0024\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0022\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0023\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0024\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0023\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0021\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0022\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0021\n",
            "61/61 [==============================] - 2s 6ms/step\n",
            "Evaluation of LSTM for Robust Scale dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 7s 12ms/step - loss: 0.3499\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0393\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0104\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0071\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0075\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0075\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0072\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0069\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0070\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0073\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0056\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0071\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0061\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0072\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0067\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0066\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0059\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0056\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0060\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0060\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0056\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0051\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0056\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0051\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0053\n",
            "61/61 [==============================] - 2s 4ms/step\n",
            "Evaluation of LSTM for Normalized dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 7s 12ms/step - loss: 0.4322\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0204\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0098\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0090\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0083\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0082\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0082\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0075\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0074\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0072\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0069\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0072\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0071\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0071\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0069\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0066\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0063\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0057\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0061\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0064\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0052\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0053\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0057\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0058\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0051\n",
            "61/61 [==============================] - 2s 4ms/step\n",
            "Evaluation of LSTM for maxAbs dataset:\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 7s 12ms/step - loss: 0.0770\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0109\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0034\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0026\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0024\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0020\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0021\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0019\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0018\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0018\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0013\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0016\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0016\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0015\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0018\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0018\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0014\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0016\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.0015\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.0015\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.0014\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.0011\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.0013\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 0s 18ms/step - loss: 0.0013\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 0.0011\n",
            "61/61 [==============================] - 2s 4ms/step\n",
            "R2 LSTM\n",
            "LinearRegression R2 before scaling : nil \n",
            " LinearRegression R2 after Standardization : 0.9990628386875663 \n",
            " LinearRegression R2 after MinMax Scaling : 0.9996773427234854 \n",
            " LinearRegression R2 after Binirization : 0.0 \n",
            " LinearRegression R2 after Quantile Scaling : 0.9911811989460058 \n",
            " LinearRegression R2 after Robust Scaling : 0.999154534111164 \n",
            " LinearRegression R2 after Normalization : 0.0 \n",
            " LinearRegression R2 after MaxAbs Scaling : 0.9995299929602843 \n",
            "\n",
            "RMSE LSTM\n",
            "LinearRegression RMSE before scaling : nil \n",
            " LinearRegression RMSE after Standardization : 0.030527485168476323 \n",
            " LinearRegression RMSE after MinMax Scaling : 0.00525819491724185 \n",
            " LinearRegression RMSE after Binirization : 0.03171956539154053 \n",
            " LinearRegression RMSE after Quantile Scaling : 0.026532383812848934 \n",
            " LinearRegression RMSE after Robust Scaling : 0.020442307974978795 \n",
            " LinearRegression RMSE after Normalization : 0.004893302917480469 \n",
            " LinearRegression RMSE after MaxAbs Scaling : 0.00607249125700948 \n",
            "\n",
            "MAPE LSTM\n",
            "LinearRegression MAPE before scaling :nil \n",
            " LinearRegression MAPE after Standardization : 0.05016478587108571 \n",
            " LinearRegression MAPE after MinMax Scaling : 5288067731.182251 \n",
            " LinearRegression MAPE after Binirization : 0.03171956539154053 \n",
            " LinearRegression MAPE after Quantile Scaling : 12896435683.266365 \n",
            " LinearRegression MAPE after Robust Scaling : 49446920247.205215 \n",
            " LinearRegression MAPE after Normalization : 0.004893302917480469 \n",
            " LinearRegression MAPE after MaxAbs Scaling : 0.010223413485696253 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Logistic regression**"
      ],
      "metadata": {
        "id": "IAXiNBOXKd5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_split(dataset):\n",
        "\n",
        "  # In this, we select the set of attributes that directly affect the dependent variables (Close) in our dataset:\n",
        "  features =  ['High', 'Low', 'Open','Adj Close']\n",
        "\n",
        "  # Then split the data between y(dependent) and X(independent) variables:\n",
        "  y = dataset['Close']\n",
        "  x = dataset[features]\n",
        "\n",
        "  \n",
        "  # After that, we split our dataset into the training set and testing set in the ratios of 80:20:\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.7, random_state=1)\n",
        "\n",
        "  # convert to numpy array logistic regrssion\n",
        "  X_train, X_test, Y_train, Y_test = np.array(X_train), np.array(X_test), np.array(Y_train), np.array(Y_test)\n",
        "\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test"
      ],
      "metadata": {
        "id": "Oj2np99AK1ZE"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_logR():\n",
        "  # split Standardized dataset\n",
        "  X_train1, X_test1, Y_train1, Y_test1 = logistic_split(standard_Stock_Data)\n",
        "\n",
        "  # split MinMax dataset\n",
        "  X_train2, X_test2, Y_train2, Y_test2, = logistic_split(minMax_Stock_Data)\n",
        "\n",
        "  # split Binirized dataset\n",
        "  X_train3, X_test3, Y_train3, Y_test3,= logistic_split(binirized_Stock_Data)\n",
        "\n",
        "  # split Quant Scale dataset\n",
        "  X_train4, X_test4, Y_train4, Y_test4, = logistic_split(Quant_Stock_Data)\n",
        "\n",
        "  # split Robust Scale dataset\n",
        "  X_train5, X_test5, Y_train5, Y_test5 = logistic_split(robust_Stock_Data)\n",
        "\n",
        "  # split Normalized dataset\n",
        "  X_train6, X_test6, Y_train6, Y_test6 = logistic_split(normalized_Stock_Data)\n",
        "\n",
        "  # split maxAbs dataset\n",
        "  X_train7, X_test7, Y_train7, Y_test7= logistic_split(maxAbs_Stock_Data)\n",
        "\n",
        "\n",
        "  #model\n",
        "  #initiate regressors \n",
        "  stan_classifier = LogisticRegression()\n",
        "  minMax_classifier = LogisticRegression()\n",
        "  bin_classifier = LogisticRegression()\n",
        "  quant_classifier = LogisticRegression()\n",
        "  rob_classifier = LogisticRegression()\n",
        "  nom_classifier = LogisticRegression()\n",
        "  maxabs_classifier = LogisticRegression()\n",
        "\n",
        "\n",
        "  # fitting models\n",
        "  stan_classifier.fit(X_train1,Y_train1)\n",
        "  minMax_classifier.fit(X_train2,Y_train2)\n",
        "  bin_classifier.fit(X_train3,Y_train3)\n",
        "  quant_classifier.fit(X_train4,Y_train4)\n",
        "  rob_classifier.fit(X_train5,Y_train5)\n",
        "  nom_classifier.fit(X_train6,Y_train6)\n",
        "  maxabs_classifier.fit(X_train7,Y_train7)\n",
        "\n",
        "  # predict\n",
        "  Y_predict1 = stan_classifier.predict(X_test1)\n",
        "  Y_predict2 = minMax_classifier.predict(X_test2)\n",
        "  Y_predict3 = bin_classifier.predict(X_test3)\n",
        "  Y_predict4 = quant_classifier.predict(X_test4)\n",
        "  Y_predict5 = rob_classifier.predict(X_test5)\n",
        "  Y_predict6 = nom_classifier.predict(X_test6)\n",
        "  Y_predict7 = maxabs_classifier.predict(X_test7)\n",
        "\n",
        "  # check accuracy\n",
        "  accuracy_stan = stan_classifier.score(X_test1, Y_test1)\n",
        "  accuracy_minmax = minMax_classifier.score(X_test2, Y_test2)\n",
        "  accuracy_bin = bin_classifier.score(X_test3, Y_test3)\n",
        "  accuracy_quant = quant_classifier.score(X_test4, Y_test4)\n",
        "  accuracy_rob = rob_classifier.score(X_test5, Y_test5)\n",
        "  accuracy_nom = nom_classifier.score(X_test6, Y_test6)\n",
        "  accuracy_maxabs = maxabs_classifier.score(X_test7, Y_test7)\n",
        "\n",
        "  print(\"ACCURACY logistic regrssion\")\n",
        "  print(\"logistic regrssion Accuracy before scaling : nil\", \n",
        "        \"\\n logistic regrssion Accuracy after Standardization :\", accuracy_stan, \n",
        "        \"\\n logistic regrssion Accuracy after MinMax Scaling :\", accuracy_minmax, \n",
        "        \"\\n logistic regrssion Accuracy after Binirization :\", accuracy_bin,\n",
        "        \"\\n logistic regrssion Accuracy after Quantile Scaling :\", accuracy_quant,\n",
        "        \"\\n logistic regrssion Accuracy after Robust Scaling :\", accuracy_rob,\n",
        "        \"\\n logistic regrssion Accuracy after Normalization :\", accuracy_nom,\n",
        "        \"\\n logistic regrssion Accuracy after MaxAbs Scaling :\", accuracy_maxabs, \"\\n\")\n",
        "  \n",
        "  \n",
        "  # check R2 score:\n",
        "  r2_1 = r2_score(Y_test1, Y_predict1)\n",
        "  r2_2 = r2_score(Y_test2, Y_predict2)\n",
        "  r2_3 = r2_score(Y_test3, Y_predict3)\n",
        "  r2_4 = r2_score(Y_test4, Y_predict4)\n",
        "  r2_5 = r2_score(Y_test5, Y_predict5)\n",
        "  r2_6 = r2_score(Y_test6, Y_predict6)\n",
        "  r2_7 = r2_score(Y_test7, Y_predict7)\n",
        "  print(\"R2 logistic regrssion\")\n",
        "  print(\"logistic regrssion R2 before scaling : nil\", \n",
        "        \"\\n logistic regrssion R2 after Standardization :\", r2_1, \n",
        "        \"\\n logistic regrssion R2 after MinMax Scaling :\", r2_2, \n",
        "        \"\\n logistic regrssion R2 after Binirization :\", r2_3,\n",
        "        \"\\n logistic regrssion R2 after Quantile Scaling :\", r2_4,\n",
        "        \"\\n logistic regrssion R2 after Robust Scaling :\", r2_5,\n",
        "        \"\\n logistic regrssion R2 after Normalization :\", r2_6,\n",
        "        \"\\n logistic regrssion R2 after MaxAbs Scaling :\", r2_7, \"\\n\")\n",
        "  \n",
        "  # Check Root Mean Squared Error\n",
        "  \n",
        "  rmse_1 = mean_squared_error(Y_test1, Y_predict1, squared=False)\n",
        "  rmse_2 = mean_squared_error(Y_test2, Y_predict2, squared=False)\n",
        "  rmse_3 = mean_squared_error(Y_test3, Y_predict3, squared=False)\n",
        "  rmse_4 = mean_squared_error(Y_test4, Y_predict4, squared=False)\n",
        "  rmse_5 = mean_squared_error(Y_test5, Y_predict5, squared=False)\n",
        "  rmse_6 = mean_squared_error(Y_test6, Y_predict6, squared=False)\n",
        "  rmse_7 = mean_squared_error(Y_test7, Y_predict7, squared=False)\n",
        "  print(\"RMSE logistic regrssion\")\n",
        "  print(\"logistic regrssion RMSE before scaling : nil\", \n",
        "        \"\\n logistic regrssion RMSE after Standardization :\", rmse_1, \n",
        "        \"\\n logistic regrssion RMSE after MinMax Scaling :\", rmse_2, \n",
        "        \"\\n logistic regrssion RMSE after Binirization :\", rmse_3,\n",
        "        \"\\n logistic regrssion RMSE after Quantile Scaling :\", rmse_4,\n",
        "        \"\\n logistic regrssion RMSE after Robust Scaling :\", rmse_5,\n",
        "        \"\\n logistic regrssion RMSE after Normalization :\", rmse_6,\n",
        "        \"\\n logistic regrssion RMSE after MaxAbs Scaling :\", rmse_7, \"\\n\")\n",
        "  \n",
        "  # check Mean Absolute Percentage Error \n",
        "  mape_1 = mean_absolute_percentage_error(Y_test1, Y_predict1)\n",
        "  mape_2 = mean_absolute_percentage_error(Y_test2, Y_predict2)\n",
        "  mape_3 = mean_absolute_percentage_error(Y_test3, Y_predict3)\n",
        "  mape_4 = mean_absolute_percentage_error(Y_test4, Y_predict4)\n",
        "  mape_5 = mean_absolute_percentage_error(Y_test5, Y_predict5)\n",
        "  mape_6 = mean_absolute_percentage_error(Y_test6, Y_predict6)\n",
        "  mape_7 = mean_absolute_percentage_error(Y_test7, Y_predict7)\n",
        "  print(\"MAPE LinearRegression\")\n",
        "  print(\"LinearRegression MAPE before scaling :\", mape_b4_lin, \n",
        "        \"\\n logistic regrssion MAPE after Standardization :\", mape_1, \n",
        "        \"\\n logistic regrssion MAPE after MinMax Scaling :\", mape_2, \n",
        "        \"\\n logistic regrssion MAPE after Binirization :\", mape_3,\n",
        "        \"\\n logistic regrssion MAPE after Quantile Scaling :\", mape_4,\n",
        "        \"\\n logistic regrssion MAPE after Robust Scaling :\", mape_5,\n",
        "        \"\\n logistic regrssion MAPE after Normalization :\", mape_6,\n",
        "        \"\\n logistic regrssion MAPE after MaxAbs Scaling :\", mape_7, \"\\n\")\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "HG6zPIuNKqBJ"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_logR()"
      ],
      "metadata": {
        "id": "Ysf1LZQuNUXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notes**\n",
        "\n",
        "Bugs in the code were eventually realised.\n",
        "\n",
        "errors: \n",
        "1. In the implementation of the data scaling methods, the initial dataset was ovewritten by the initscaled dataset, this caused the scaling methods called after to scale a dataset previously scaled.  \n",
        "\n",
        "2. the use of logistic regression on time series data, after further research it eas discovered that the logistic regresion model is mainly used in classification problems, therefore it would not be a fitting model for this scenario \n",
        "\n",
        "Solutions. \n",
        "1. using the .copy() function in conjunction with variating the variable names in each function solved the issue of overwriting the intial dataset and providedd better results across models \n",
        "\n",
        "2. Proposing the use of a convolutional neural network to further thest the effects of data scaling methods on the accuracy of ml models on stock price prediction \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gpE8RbdeOcnL"
      }
    }
  ]
}